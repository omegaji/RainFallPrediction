{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd04679094c71e58fd5daa32654c6d4dcc218cb243910207196539a7dfc04a8a332",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(\"combined.csv\")\n",
    "\n",
    "def convertToFloat(x):\n",
    "    x=x.strip()\n",
    "    if x==\"-\" or x==\"NR\" or x=='' or x==\".\" or x==\"\" or x==' ':\n",
    "        return 0.01\n",
    "    else:\n",
    "        \n",
    "        return float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"rain\"]=df[\"Rain\"].apply(convertToFloat)\n",
    "import datetime\n",
    "df[\"month\"]=df[\"Date\"].apply(lambda x:datetime.datetime.strptime(x,\"%Y-%m-%d\").month)\n",
    "df[\"year\"]=df[\"Date\"].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").year)\n",
    "df[\"day\"]=df[\"Date\"].apply(lambda x: datetime.datetime.strptime(x,\"%Y-%m-%d\").day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isRain(x):\n",
    "    if x>100:\n",
    "        return 5\n",
    "    if x>50:\n",
    "        return 4\n",
    "    if x>25:\n",
    "        return 3\n",
    "    if x>2:\n",
    "        return 2\n",
    "    elif x!=0.01:\n",
    "        return 1\n",
    " \n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_rain\"]=df[\"rain\"].apply(isRain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummydf=pd.get_dummies(df[[\"District\",\"rain\",\"month\",\"day\",\"year\",\"is_rain\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Al_df=df[df.District==\"Alangayam\"][[\"rain\",\"month\",\"day\",\"year\",\"is_rain\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=dummydf.pop(\"rain\")\n",
    "x=dummydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=Al_df.pop(\"rain\")\n",
    "x=Al_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(x , y, test_size=0.33, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.model_selection import train_test_split\n",
    " from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x , y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-38-227f16517e95>:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_train[\"month\"]=tempdf[0]\n<ipython-input-38-227f16517e95>:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_train[\"day\"]=tempdf[1]\n<ipython-input-38-227f16517e95>:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_train[\"year\"]=tempdf[2]\n<ipython-input-38-227f16517e95>:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_test[\"month\"]=tempdf[0]\n<ipython-input-38-227f16517e95>:10: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_test[\"day\"]=tempdf[1]\n<ipython-input-38-227f16517e95>:11: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_test[\"year\"]=tempdf[2]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "tempdf=pd.DataFrame(scaler.fit_transform(X_train[[\"month\",\"day\",\"year\"]].values))\n",
    "X_train[\"month\"]=tempdf[0]\n",
    "X_train[\"day\"]=tempdf[1]\n",
    "X_train[\"year\"]=tempdf[2]\n",
    "\n",
    "scalertest=MinMaxScaler()\n",
    "tempdf=pd.DataFrame(scaler.fit_transform(X_test[[\"month\",\"day\",\"year\"]].values))\n",
    "X_test[\"month\"]=tempdf[0]\n",
    "X_test[\"day\"]=tempdf[1]\n",
    "X_test[\"year\"]=tempdf[2]\n",
    "\n",
    "# X_train=scaler.fit_transform(X_train)\n",
    "# scaler2 = StandardScaler()\n",
    "\n",
    "# X_test=scaler2.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        0.366667\n",
       "1        0.033333\n",
       "2        0.666667\n",
       "3        0.066667\n",
       "4        0.600000\n",
       "           ...   \n",
       "31010    0.666667\n",
       "31011    0.166667\n",
       "31012    0.166667\n",
       "31013    0.633333\n",
       "31014    0.000000\n",
       "Name: 1, Length: 31015, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "tempdf[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.2034639652025696"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test,reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1.404206625853364"
      ]
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 0.21894508, 12.46740162, -0.14647121, ..., 12.94425225,\n",
       "        0.38613749,  0.3628996 ])"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[00:05:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/objective/regression_obj.cu:171: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, eta=0.7, gamma=0,\n",
       "             gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.699999988, max_delta_step=0, max_depth=20,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=50, n_jobs=12, num_parallel_tree=1,\n",
       "             objective='reg:linear', random_state=123, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=123, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "xgb_r = xg.XGBRegressor(objective ='reg:linear',    \n",
    "                  n_estimators = 50, seed = 123,max_depth=20,eta=0.7)\n",
    "   \n",
    "# Fitting the model\n",
    "xgb_r.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\om purohit\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pred = xgb_r.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    # y_true, y_pred = check_arrays(y_true, y_pred)\n",
    "\n",
    "    ## Note: does not handle mix 1d representation\n",
    "    #if _is_1d(y_true): \n",
    "    #    y_true, y_pred = _check_1d_array(y_true, y_pred)\n",
    "\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "mean_absolute_percentage_error( y_train,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8999667648096353"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\om purohit\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pred_test=xgb_r.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pred_test' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-a289fb863c7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pred_test' is not defined"
     ]
    }
   ],
   "source": [
    "mean_absolute_error(y_test,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={\"orig\":y_test,\"pred_test\":pred}\n",
    "preddf=pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        orig  pred_test\n",
       "35844   0.01   0.010001\n",
       "18346   0.01   0.010001\n",
       "8140   56.00  60.217617\n",
       "43290   0.01   0.010001\n",
       "40376   0.01   0.010001\n",
       "...      ...        ...\n",
       "1274    0.01   0.010001\n",
       "13166   0.01   0.010001\n",
       "45618   0.01   0.010001\n",
       "44814   0.01   0.010001\n",
       "12538   7.00   4.354761\n",
       "\n",
       "[15277 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>orig</th>\n      <th>pred_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>35844</th>\n      <td>0.01</td>\n      <td>0.010001</td>\n    </tr>\n    <tr>\n      <th>18346</th>\n      <td>0.01</td>\n      <td>0.010001</td>\n    </tr>\n    <tr>\n      <th>8140</th>\n      <td>56.00</td>\n      <td>60.217617</td>\n    </tr>\n    <tr>\n      <th>43290</th>\n      <td>0.01</td>\n      <td>0.010001</td>\n    </tr>\n    <tr>\n      <th>40376</th>\n      <td>0.01</td>\n      <td>0.010001</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1274</th>\n      <td>0.01</td>\n      <td>0.010001</td>\n    </tr>\n    <tr>\n      <th>13166</th>\n      <td>0.01</td>\n      <td>0.010001</td>\n    </tr>\n    <tr>\n      <th>45618</th>\n      <td>0.01</td>\n      <td>0.010001</td>\n    </tr>\n    <tr>\n      <th>44814</th>\n      <td>0.01</td>\n      <td>0.010001</td>\n    </tr>\n    <tr>\n      <th>12538</th>\n      <td>7.00</td>\n      <td>4.354761</td>\n    </tr>\n  </tbody>\n</table>\n<p>15277 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "preddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "eps = 5\n",
    "svr = LinearSVR(epsilon=eps, C=0.01, fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\om purohit\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearSVR(C=0.01, epsilon=5)"
      ]
     },
     "metadata": {},
     "execution_count": 180
    }
   ],
   "source": [
    "svr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5.816683235951595"
      ]
     },
     "metadata": {},
     "execution_count": 183
    }
   ],
   "source": [
    "mean_absolute_error(y_test,svr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "50.42033054947053"
      ]
     },
     "metadata": {},
     "execution_count": 186
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\om purohit\\anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0006024791217659378"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "mean_absolute_error(y_train,xgb_r.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}